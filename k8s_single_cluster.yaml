- name: Initialize master and worker nodes
  hosts: all
  tasks:

   - name: disable UFW firewall for labs
     service:
        name: ufw
        state: stopped
        enabled: false

   - name: Disable SWAP
     shell: |
       swapoff -a

   - name: Disable SWAP in fstab
     lineinfile:
       path: /etc/fstab
       regexp: '^.*swap.*$'
       line: '#\0'
       backrefs: yes
   - name: Ensure br_netfilter module is loaded
     modprobe:
       name: br_netfilter
       state: present

   - name: Ensure sysctl configuration for Kubernetes is present
     lineinfile:
       path: /etc/sysctl.d/kubernetes.conf
       state: present
       create: yes
       line: "{{ item }}"
     loop:
       - 'net.bridge.bridge-nf-call-ip6tables = 1'
       - 'net.bridge.bridge-nf-call-iptables = 1'

   - name: Apply sysctl parameters
     sysctl:
       name: "{{ item }}"
       value: 1
       state: present
     loop:
       - net.bridge.bridge-nf-call-ip6tables
       - net.bridge.bridge-nf-call-iptables

   - name: Reload sysctl
     command: sysctl --system
     args:
       warn: no
   - name: Installation of apt-utils
     apt:
      name: apt-transport-https
      state: present
      update_cache: yes

   - name: Adding Docker GPG key
     ansible.builtin.apt_key:
       url: https://download.docker.com/linux/ubuntu/gpg
       state: present

   - name: Adding Docker Repository
     apt_repository:
       repo: deb [arch=amd64] https://download.docker.com/linux/ubuntu {{ ansible_distribution_release }} stable
       state: present

   - name: Installation of Docker
     apt:
      name: "{{ item }}"
      state: present
     loop:
       - docker-ce
       - docker-ce-cli
       - containerd.io
       - docker-compose

   - name: Setting value of SystemdCgroup
     shell: |
       containerd config default | sudo tee /etc/containerd/config.toml | grep SystemdCgroup
       sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml

   - name : Starting Service of Docker
     service:
       name: docker
       state: started
       enabled: yes



#k8s tools repo
# - name: import k8s tools script
#    script: /root/cta/repo.sh
   - name: add k8s repo script
     shell: |
       apt-get update
       apt-get install -y apt-transport-https ca-certificates curl gnupg
       if [ ! -d /etc/apt/keyrings ]; then
       mkdir -p -m 755 /etc/apt/keyrings
       fi

       if [ ! -f /etc/apt/keyrings/kubernetes-apt-keyring.gpg ]; then
       curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
       fi
       echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /' | tee /etc/apt/sources.list.d/kubernetes.list

       apt-get update
     args:
       executable: /bin/bash




#install k8s tools
   - name: Install kubelet and kubeadm
     apt:
       name: "{{ item }}"
       state: present
     loop:
       - kubeadm
       - kubelet

   - name: start kubelet
     service:
       name: kubelet
       enabled: yes
       state: started

   - name: install kubectl
     apt:
       name: kubectl
       state: present
     when: "'masters' in group_names"
# restart services
   - name: restart services
     service: 
       name: "{{ item }}"
       state: restarted
     with_items:
       - docker.service
       - containerd.service


#cluster initialise 

   - name: initialize K8S cluster
     command: kubeadm init --pod-network-cidr=172.16.0.0/16 --apiserver-advertise-address=192.168.3.53 --ignore-preflight-errors=all
     when: "'masters' in group_names"

   - name: create .kube directoryi and copy kube config file
     command: "{{ item }}"
     loop:
       -  mkdir -p $HOME/.kube
       -  cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
       -  chown root:root $HOME/.kube/config
     when: "'masters' in group_names"

# Deploy Calico Network Pods

   - name: Create Calico Tigera operator using kubectl
     command:
       kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.2/manifests/tigera-operator.yaml
     when: inventory_hostname == "master1"

   - name: Download custom-resources.yaml using wget
     get_url:
       url: https://raw.githubusercontent.com/projectcalico/calico/v3.27.2/manifests/custom-resources.yaml
       dest: /tmp/custom-resources.yaml
     when: inventory_hostname == "master1"

   - name: Modify CIDR for pods in the custom-resources.yaml file
     replace:
       path: /tmp/custom-resources.yaml
       regexp: 'cidr: 192.168.0.0/16'
       replace: 'cidr: 172.16.0.0/16'  # Update to your custom CIDR
     when: inventory_hostname == "master1"

   - name: Apply custom-resources.yaml using kubectl
     command:
       kubectl apply -f /tmp/custom-resources.yaml
     when: inventory_hostname == "master1"

     #- name: install Pod network **** OLD WAY AND NOT WORKING ****
     #become: yes
     #command: kubectl --kubeconfig=/etc/kubernetes/admin.conf create -f https://docs.projectcalico.org/v3.15/manifests/calico.yaml
     #when: "'masters' in group_names"
 

#join worker nodes

   - name: get join command
     shell: kubeadm token create --print-join-command
     register: join_command_raw
     when: "'masters' in group_names"

   - name: set join command
     set_fact:
       join_command: "{{ join_command_raw.stdout_lines[0] }}"
     when: "'masters' in group_names"

   - name: join cluster
     shell: "{{ hostvars['master1'].join_command }} --ignore-preflight-errors all  >> node_joined.txt"
     args:
       chdir: $HOME
       creates: node_joined.txt
     when: "'workers' in group_names"
 
#enable auto completion 

   - name: enable auto completion
     shell: |
       source <(kubectl completion bash)
       echo "source <(kubectl completion bash)" >> ~/.bashrc
       echo "alias k=kubectl" >> ~/.bash_profile
       echo "complete -F __start_kubectl k" >> ~/.bash_profile
       source ~/.bash_profile
       source ~/.bashrc
     args:
       executable: /bin/bash
     when: "'masters' in group_names"
   
#label worker nodes
   
   - name: label worker nodes
     command: "{{ item }}"
     with_items:
       - kubectl label node worker1 node-role.kubernetes.io/worker=worker
       - kubectl label node worker2 node-role.kubernetes.io/worker=worker

     when: "'masters' in group_names"
 
...
        



